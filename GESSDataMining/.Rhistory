gessData <- gessData[, c(1,2,19,3:18)]
# gather the columns to make one feature for all the responses
# this will ease the cleaning process
gessData <- melt(gessData, measure.vars = names(gessData)[4:length(gessData)], variable.name = "attribute", value.name = "value")
# next is to split the responses delimited by ]
# first, create names for the features where the splitted strings will be dumped
names <- paste0("v", 1:22)
gessData[, c(names) := tstrsplit(value, "]", fixed = TRUE)] # split delimited by ]
gessData <- gessData[, -"value"]
# gather the variables again in one column
gessData <- melt(gessData, measure.vars = names(gessData)[5:length(gessData)], variable.name = "attribute2", value.name = "value")
gessData <- gessData[, -"attribute2"]
gessData <- gessData[!(is.na(gessData$value)),] # remove NAs
gessData$value <- paste(gessData$value, "-17", sep = "")
# lookup the values in the codes data - to identify the descriptions
names(codeData)[c(3,4)] <- c("value", "decode") # change the column names to match data
codeData$value <- as.character(codeData$value)
gessData$value <- as.character(gessData$value)
codeData <- unique(codeData)
gessData <- merge(gessData, codeData, by = "value", all.x = TRUE)
gessData <- gessData[,-c(1,6,7)] # remove the unnecessary coulmns
# dummify the categories
names(gessData) <- c("id", "country", "attended", "attribute", "value")
gessData <- dcast(gessData, id + country + attended ~ value)
gessData <- gessData[, c(3,2,4:86)]
View(gessData)
## This is a data mining project for GESS
## Data is based on 2017
## Author: Grejell Segura
rm(list = ls())
library(data.table)
library(tidyverse)
library(caret)
atdData <- fread("./dta/attd.csv", sep = ",") # attended data
nsData <- fread("./dta/ns.csv", sep = ",") # no show data
codeData <- fread("./dta/codes_v2.csv", sep = ",") # codes
regionData <- fread("./dta/region.csv", sep = ",") # regions data
# create an attendance columns
atdData$attended <- "atd"
nsData$attended <- "ns"
atdData[] <- lapply(atdData, function(x) as.character(x))  # change all features to characters to be able to join to nsData
nsData[] <- lapply(nsData, function(x) as.character(x))  # change all features to characters to be able to join atdData
# combine data
gessData <- rbind(atdData, nsData)
# summarize
summary(gessData)
any(is.na(gessData))
str(gessData)
# arrange columns
gessData <- gessData[, c(1,2,19,3:18)]
# gather the columns to make one feature for all the responses
# this will ease the cleaning process
gessData <- melt(gessData, measure.vars = names(gessData)[4:length(gessData)], variable.name = "attribute", value.name = "value")
# next is to split the responses delimited by ]
# first, create names for the features where the splitted strings will be dumped
names <- paste0("v", 1:22)
gessData[, c(names) := tstrsplit(value, "]", fixed = TRUE)] # split delimited by ]
gessData <- gessData[, -"value"]
# gather the variables again in one column
gessData <- melt(gessData, measure.vars = names(gessData)[5:length(gessData)], variable.name = "attribute2", value.name = "value")
gessData <- gessData[, -"attribute2"]
gessData <- gessData[!(is.na(gessData$value)),] # remove NAs
gessData$value <- paste(gessData$value, "-17", sep = "")
# lookup the values in the codes data - to identify the descriptions
names(codeData)[c(3,4)] <- c("value", "decode") # change the column names to match data
codeData$value <- as.character(codeData$value)
gessData$value <- as.character(gessData$value)
codeData <- unique(codeData)
gessData <- merge(gessData, codeData, by = "value", all.x = TRUE)
gessData <- gessData[,-c(1,6,7)] # remove the unnecessary coulmns
# dummify the categories
names(gessData) <- c("id", "country", "attended", "attribute", "value")
gessData <- dcast(gessData, id + country + attended ~ value)
gessData <- gessData[, c(3,2,4:86)]
#gessData[,c(3:85)] <- lapply(gessData[,c(3:85)], function(x) ifelse(is.na(x), 0, 1))
fwrite(gessData, "./dta/gessData.csv", row.names = FALSE)
View(gessData)
# This is the machine learning part
# the algorithm used is XGBoost
rm(list = ls())
library(xgboost)
library(caret)
# load the pre-processed data
gessData <- fread("./dta/gessData.csv", sep = ",")
names(gessData)[1] <- "label"
gessData$label <- ifelse(gessData$label == "atd", 1, 0) # change labels to 1 if attended 0 if no show
gessData <- gessData[, -"country"]
# dummy <- dummyVars(~., gessData)
# gessData <- predict(dummy, gessData)
# gessData <- as.data.frame(gessData)
# gessData[] <- lapply(gessData, function(x) as.numeric(x))
#################################
d <- 1:nrow(gessData)
index <- sample(d, round(nrow(gessData)*.7))
#gessData[] <- lapply(gessData, function(x) as.numeric(x))
train_dta <- gessData[index, ]
test_dta <- gessData[-index, ]
## XGBOOST ---
train_1 <- train_dta[,2:length(gessData)]
test_1 <- test_dta[,2:length(gessData)]
train_2 <- train_dta[, 1]
test_2 <- test_dta[, 1]
length(train_2)
train_1[] <- lapply(train_1, function(x) as.numeric(x))
test_1[] <- lapply(test_1, function(x) as.numeric(x))
xgtree_ <- xgboost(as.matrix(train_1), as.matrix(train_2),
booster = 'gbtree',
objective = 'multi:softmax',
num_class = 2,
max.depth = 6,
eta = 0.0001,
nthread = 8,
nrounds = 300,
min_child_weight = 1,
subsample = 0.5,
colsample_bytree = 1,
num_parallel_tree = 1)
save(xgtree_, file = "./model/xgb_model.rda")
load("./model/xgb_model.rda")
#predict gbtree ----------------
pred_xgtree_ <- predict(xgtree_, as.matrix(test_1))
msexgtree_ <- table(pred_xgtree_, unlist(test_2))
msexgtree_
##compute accuracy
wrong <- ifelse(abs(test_2 - pred_xgtree_) == 0, 1, 0)
error_xg <- sum(wrong) / nrow(test_2)
error_xg
## This is a data mining project for GESS
## Data is based on 2017
## Author: Grejell Segura
rm(list = ls())
library(data.table)
library(tidyverse)
library(caret)
atdData <- fread("./dta/attd.csv", sep = ",") # attended data
nsData <- fread("./dta/ns.csv", sep = ",") # no show data
codeData <- fread("./dta/codes_v2.csv", sep = ",") # codes
regionData <- fread("./dta/region.csv", sep = ",") # regions data
# create an attendance columns
atdData$attended <- "atd"
nsData$attended <- "ns"
atdData[] <- lapply(atdData, function(x) as.character(x))  # change all features to characters to be able to join to nsData
nsData[] <- lapply(nsData, function(x) as.character(x))  # change all features to characters to be able to join atdData
# combine data
gessData <- rbind(atdData, nsData)
# summarize
summary(gessData)
any(is.na(gessData))
str(gessData)
# arrange columns
gessData <- gessData[, c(1,2,19,3:18)]
# gather the columns to make one feature for all the responses
# this will ease the cleaning process
gessData <- melt(gessData, measure.vars = names(gessData)[4:length(gessData)], variable.name = "attribute", value.name = "value")
# next is to split the responses delimited by ]
# first, create names for the features where the splitted strings will be dumped
names <- paste0("v", 1:22)
gessData[, c(names) := tstrsplit(value, "]", fixed = TRUE)] # split delimited by ]
gessData <- gessData[, -"value"]
# gather the variables again in one column
gessData <- melt(gessData, measure.vars = names(gessData)[5:length(gessData)], variable.name = "attribute2", value.name = "value")
gessData <- gessData[, -"attribute2"]
gessData <- gessData[!(is.na(gessData$value)),] # remove NAs
gessData$value <- paste(gessData$value, "-17", sep = "")
# lookup the values in the codes data - to identify the descriptions
names(codeData)[c(3,4)] <- c("value", "decode") # change the column names to match data
codeData$value <- as.character(codeData$value)
gessData$value <- as.character(gessData$value)
codeData <- unique(codeData)
gessData <- merge(gessData, codeData, by = "value", all.x = TRUE)
gessData <- gessData[,-c(1,6,7)] # remove the unnecessary coulmns
# dummify the categories
names(gessData) <- c("id", "country", "attended", "attribute", "value")
regionData
names(regionData)[1] <- "country"
gessData <- merge(gessData, regionData, by = "country", all.x = TRUE)
View(regionData)
str(regionData)
gessData$Region[gessData$country == "United Arab Emirates"] <- "UAE"
gessData <- gessData[, c(2:6)]
gessData <- dcast(gessData, id + Region + attended ~ value)
gessData <- gessData[, c(3,2,4:86)]
## This is a data mining project for GESS
## Data is based on 2017
## Author: Grejell Segura
rm(list = ls())
library(data.table)
library(tidyverse)
library(caret)
atdData <- fread("./dta/attd.csv", sep = ",") # attended data
nsData <- fread("./dta/ns.csv", sep = ",") # no show data
codeData <- fread("./dta/codes_v2.csv", sep = ",") # codes
regionData <- fread("./dta/region.csv", sep = ",") # regions data
# create an attendance columns
atdData$attended <- "atd"
nsData$attended <- "ns"
atdData[] <- lapply(atdData, function(x) as.character(x))  # change all features to characters to be able to join to nsData
nsData[] <- lapply(nsData, function(x) as.character(x))  # change all features to characters to be able to join atdData
# combine data
gessData <- rbind(atdData, nsData)
# summarize
summary(gessData)
any(is.na(gessData))
str(gessData)
# arrange columns
gessData <- gessData[, c(1,2,19,3:18)]
# gather the columns to make one feature for all the responses
# this will ease the cleaning process
gessData <- melt(gessData, measure.vars = names(gessData)[4:length(gessData)], variable.name = "attribute", value.name = "value")
# next is to split the responses delimited by ]
# first, create names for the features where the splitted strings will be dumped
names <- paste0("v", 1:22)
gessData[, c(names) := tstrsplit(value, "]", fixed = TRUE)] # split delimited by ]
gessData <- gessData[, -"value"]
# gather the variables again in one column
gessData <- melt(gessData, measure.vars = names(gessData)[5:length(gessData)], variable.name = "attribute2", value.name = "value")
gessData <- gessData[, -"attribute2"]
gessData <- gessData[!(is.na(gessData$value)),] # remove NAs
gessData$value <- paste(gessData$value, "-17", sep = "")
# lookup the values in the codes data - to identify the descriptions
names(codeData)[c(3,4)] <- c("value", "decode") # change the column names to match data
codeData$value <- as.character(codeData$value)
gessData$value <- as.character(gessData$value)
codeData <- unique(codeData)
gessData <- merge(gessData, codeData, by = "value", all.x = TRUE)
gessData <- gessData[,-c(1,6,7)] # remove the unnecessary coulmns
# dummify the categories
names(gessData) <- c("id", "country", "attended", "attribute", "value")
names(regionData)[1] <- "country"
gessData <- merge(gessData, regionData, by = "country", all.x = TRUE)
gessData$Region[gessData$country == "United Arab Emirates"] <- "UAE"
gessData <- gessData[, c(2:6)]
gessData <- dcast(gessData, id + Region + attended ~ value)
gessData <- gessData[, c(3,2,4:86)]
fwrite(gessData, "./dta/gessData.csv", row.names = FALSE)
rm(list = ls())
library(xgboost)
library(caret)
# load the pre-processed data
gessData <- fread("./dta/gessData.csv", sep = ",")
names(gessData)[1] <- "label"
gessData$label <- ifelse(gessData$label == "atd", 1, 0) # change labels to 1 if attended 0 if no show
gessData <- gessData[, -"country"]
# dummy <- dummyVars(~., gessData)
# gessData <- predict(dummy, gessData)
# gessData <- as.data.frame(gessData)
# gessData[] <- lapply(gessData, function(x) as.numeric(x))
#################################
d <- 1:nrow(gessData)
index <- sample(d, round(nrow(gessData)*.7))
#gessData[] <- lapply(gessData, function(x) as.numeric(x))
train_dta <- gessData[index, ]
test_dta <- gessData[-index, ]
## XGBOOST ---
train_1 <- train_dta[,2:length(gessData)]
test_1 <- test_dta[,2:length(gessData)]
train_2 <- train_dta[, 1]
test_2 <- test_dta[, 1]
length(train_2)
train_1[] <- lapply(train_1, function(x) as.numeric(x))
test_1[] <- lapply(test_1, function(x) as.numeric(x))
xgtree_ <- xgboost(as.matrix(train_1), as.matrix(train_2),
booster = 'gbtree',
objective = 'multi:softmax',
num_class = 2,
max.depth = 6,
eta = 0.0001,
nthread = 8,
nrounds = 300,
min_child_weight = 1,
subsample = 0.5,
colsample_bytree = 1,
num_parallel_tree = 1)
save(xgtree_, file = "./model/xgb_model.rda")
load("./model/xgb_model.rda")
#predict gbtree ----------------
pred_xgtree_ <- predict(xgtree_, as.matrix(test_1))
msexgtree_ <- table(pred_xgtree_, unlist(test_2))
msexgtree_
##compute accuracy
wrong <- ifelse(abs(test_2 - pred_xgtree_) == 0, 1, 0)
error_xg <- sum(wrong) / nrow(test_2)
error_xg
# load the pre-processed data
gessData <- fread("./dta/gessData.csv", sep = ",")
names(gessData)[1] <- "label"
gessData$label <- ifelse(gessData$label == "atd", 1, 0) # change labels to 1 if attended 0 if no show
gessData <- gessData[, -"country"]
# dummy <- dummyVars(~., gessData)
gessData <- fread("./dta/gessData.csv", sep = ",")
names(gessData)[1] <- "label"
gessData$label <- ifelse(gessData$label == "atd", 1, 0) # change labels to 1 if attended 0 if no show
View(gessData)
# load the pre-processed data
gessData <- fread("./dta/gessData.csv", sep = ",", header = TRUE)
View(gessData)
names(gessData)[1] <- "label"
gessData$label <- ifelse(gessData$label == "atd", 1, 0) # change labels to 1 if attended 0 if no show
dummy <- dummyVars(~., gessData)
gessData <- predict(dummy, gessData)
gessData <- as.data.frame(gessData)
gessData <- gessData[, -"Region"]
gessData <- gessData[, -c("Region")]
gessData <- gessData[, -2]
#################################
d <- 1:nrow(gessData)
index <- sample(d, round(nrow(gessData)*.7))
#gessData[] <- lapply(gessData, function(x) as.numeric(x))
train_dta <- gessData[index, ]
test_dta <- gessData[-index, ]
## XGBOOST ---
train_1 <- train_dta[,2:length(gessData)]
test_1 <- test_dta[,2:length(gessData)]
train_2 <- train_dta[, 1]
test_2 <- test_dta[, 1]
length(train_2)
train_1[] <- lapply(train_1, function(x) as.numeric(x))
test_1[] <- lapply(test_1, function(x) as.numeric(x))
xgtree_ <- xgboost(as.matrix(train_1), as.matrix(train_2),
booster = 'gbtree',
objective = 'multi:softmax',
num_class = 2,
max.depth = 6,
eta = 0.0001,
nthread = 8,
nrounds = 300,
min_child_weight = 1,
subsample = 0.5,
colsample_bytree = 1,
num_parallel_tree = 1)
save(xgtree_, file = "./model/xgb_model.rda")
load("./model/xgb_model.rda")
pred_xgtree_ <- predict(xgtree_, as.matrix(test_1))
msexgtree_ <- table(pred_xgtree_, unlist(test_2))
msexgtree_
wrong <- ifelse(abs(test_2 - pred_xgtree_) == 0, 1, 0)
error_xg <- sum(wrong) / nrow(test_2)
error_xg
wrong
error_xg <- sum(wrong) / nrow(test_2)
error_xg
error_xg <- sum(wrong) / length(test_2)
error_xg
# This is the machine learning part
# the algorithm used is XGBoost
rm(list = ls())
library(xgboost)
library(caret)
# load the pre-processed data
gessData <- fread("./dta/gessData.csv", sep = ",", header = TRUE)
names(gessData)[1] <- "label"
gessData$label <- ifelse(gessData$label == "atd", 1, 0) # change labels to 1 if attended 0 if no show
dummy <- dummyVars(~., gessData)
gessData <- predict(dummy, gessData)
gessData <- as.data.frame(gessData)
gessData <- gessData[, -2]
rm(list = ls())
library(xgboost)
library(caret)
library(data.table)
# load the pre-processed data
gessData <- fread("./dta/gessData.csv", sep = ",", header = TRUE)
names(gessData)[1] <- "label"
gessData$label <- ifelse(gessData$label == "atd", 1, 0) # change labels to 1 if attended 0 if no show
dummy <- dummyVars(~., gessData)
gessData <- predict(dummy, gessData)
gessData <- as.data.frame(gessData)
gessData <- gessData[, -2]
#################################
d <- 1:nrow(gessData)
index <- sample(d, round(nrow(gessData)*.7))
#gessData[] <- lapply(gessData, function(x) as.numeric(x))
train_dta <- gessData[index, ]
test_dta <- gessData[-index, ]
## XGBOOST ---
train_1 <- train_dta[,2:length(gessData)]
test_1 <- test_dta[,2:length(gessData)]
train_2 <- train_dta[, 1]
test_2 <- test_dta[, 1]
length(train_2)
train_1[] <- lapply(train_1, function(x) as.numeric(x))
test_1[] <- lapply(test_1, function(x) as.numeric(x))
View(train_1)
train_1 <- dist(train_1, method = "euclidean") ##expirement on the method to see better result
# This is the machine learning part
# the algorithm used is XGBoost
rm(list = ls())
library(xgboost)
library(caret)
library(data.table)
# load the pre-processed data
gessData <- fread("./dta/gessData.csv", sep = ",", header = TRUE)
names(gessData)[1] <- "label"
gessData$label <- ifelse(gessData$label == "atd", 1, 0) # change labels to 1 if attended 0 if no show
dummy <- dummyVars(~., gessData)
gessData <- predict(dummy, gessData)
gessData <- as.data.frame(gessData)
gessData <- gessData[, -2]
# gessData[] <- lapply(gessData, function(x) as.numeric(x))
#################################
d <- 1:nrow(gessData)
index <- sample(d, round(nrow(gessData)*.7))
#gessData[] <- lapply(gessData, function(x) as.numeric(x))
train_dta <- gessData[index, ]
test_dta <- gessData[-index, ]
## XGBOOST ---
train_1 <- train_dta[,2:length(gessData)]
test_1 <- test_dta[,2:length(gessData)]
train_2 <- train_dta[, 1]
test_2 <- test_dta[, 1]
length(train_2)
train_1[] <- lapply(train_1, function(x) as.numeric(x))
test_1[] <- lapply(test_1, function(x) as.numeric(x))
### heirarchical clustering ###
train_1.dist <- dist(train_1, method = "euclidean") ##expirement on the method to see better result
hcluster <- hclust(train_1, method = "mcquitty")
hcluster <- hclust(train_1.dist, method = "mcquitty")
plot(hcluster)
group <- cutree(hcluster, 7)
group
train_1$group <- group
summary(group)
group <- cutree(hcluster, 4)
group
train_1$group <- group
summary(group)
table(train_2, group)
group <- cutree(hcluster, 2)
train_1$group <- group
table(train_2, group)
hcluster <- hclust(train_1.dist, method = "ward.D")
plot(hcluster)
group <- cutree(hcluster, 2)
table(train_2, group)
hcluster <- hclust(train_1.dist, method = "ward.D2")
plot(hcluster)
group <- cutree(hcluster, 2)
table(train_2, group)
hcluster <- hclust(train_1.dist, method = "single")
plot(hcluster)
group <- cutree(hcluster, 2)
table(train_2, group)
hcluster <- hclust(train_1.dist, method = "complete")
plot(hcluster)
group <- cutree(hcluster, 2)
table(train_2, group)
hcluster <- hclust(train_1.dist, method = "average")
plot(hcluster)
group <- cutree(hcluster, 2)
table(train_2, group)
hcluster <- hclust(train_1.dist, method = "centroid")
plot(hcluster)
group <- cutree(hcluster, 2)
table(train_2, group)
rm(list = ls())
library(xgboost)
library(caret)
library(data.table)
# load the pre-processed data
gessData <- fread("./dta/gessData.csv", sep = ",", header = TRUE)
names(gessData)[1] <- "label"
gessData$label <- ifelse(gessData$label == "atd", 1, 0) # change labels to 1 if attended 0 if no show
dummy <- dummyVars(~., gessData)
gessData <- predict(dummy, gessData)
gessData <- as.data.frame(gessData)
gessData <- gessData[, -2]
# gessData[] <- lapply(gessData, function(x) as.numeric(x))
#################################
d <- 1:nrow(gessData)
index <- sample(d, round(nrow(gessData)*.7))
#gessData[] <- lapply(gessData, function(x) as.numeric(x))
train_dta <- gessData[index, ]
test_dta <- gessData[-index, ]
## XGBOOST ---
train_1 <- train_dta[,2:length(gessData)]
test_1 <- test_dta[,2:length(gessData)]
train_2 <- train_dta[, 1]
test_2 <- test_dta[, 1]
length(train_2)
train_1[] <- lapply(train_1, function(x) as.numeric(x))
test_1[] <- lapply(test_1, function(x) as.numeric(x))
### heirarchical clustering ###
train_1.dist <- dist(train_1, method = "euclidean") ##expirement on the method to see better result
hcluster <- hclust(train_1.dist, method = "centroid")
plot(hcluster)
group <- cutree(hcluster, 2)
table(train_2, group)
hcluster <- hclust(train_1.dist, method = "median")
plot(hcluster)
group <- cutree(hcluster, 2)
table(train_2, group)
hcluster <- hclust(train_1.dist, method = "mcquitty")
plot(hcluster)
group <- cutree(hcluster, 2)
table(train_2, group)
group <- cutree(hcluster, 3)
table(train_2, group)
group <- cutree(hcluster, 4)
table(train_2, group)
group <- cutree(hcluster, 5)
table(train_2, group)
group <- cutree(hcluster, 6)
table(train_2, group)
hcluster <- hclust(train_1.dist, method = "ward.D")
plot(hcluster)
table(train_2, group)
group <- cutree(hcluster, 6)
group <- cutree(hcluster, 2)
table(train_2, group)
rect.hclust(hcluster, k = 2, border = "red")
group <- cutree(hcluster, 4)
rect.hclust(hcluster, k = 4, border = "red")
